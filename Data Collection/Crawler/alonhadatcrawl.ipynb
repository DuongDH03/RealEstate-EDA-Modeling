{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b3d88e",
   "metadata": {},
   "source": [
    "## Let's crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c3760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: undetected-chromedriver in c:\\users\\phuon\\anaconda3\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: selenium in c:\\users\\phuon\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: requests in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from undetected-chromedriver) (2.31.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from undetected-chromedriver) (15.0.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (4.13.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from requests->undetected-chromedriver) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\phuon\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\phuon\\anaconda3\\lib\\site-packages\\torchlight-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "%pip install undetected-chromedriver selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling page 2...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_2.jsonl\n",
      "Crawling page 3...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_3.jsonl\n",
      "Crawling page 4...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_4.jsonl\n",
      "Crawling page 5...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_5.jsonl\n",
      "Crawling page 6...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_6.jsonl\n",
      "Crawling page 7...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_7.jsonl\n",
      "Crawling page 8...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_8.jsonl\n",
      "Crawling page 9...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_9.jsonl\n",
      "Crawling page 10...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_10.jsonl\n",
      "Crawling page 11...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_11.jsonl\n",
      "Crawling page 12...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_12.jsonl\n",
      "Crawling page 13...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_13.jsonl\n",
      "Crawling page 14...\n",
      "Saved 20 items to ../Datasets/alonhadat.com/json_new\\page_14.jsonl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found for page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m     random_sleep(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Be polite to the server\u001b[39;00m\n\u001b[0;32m     96\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36mrandom_sleep\u001b[1;34m(min_seconds, max_seconds)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_sleep\u001b[39m(min_seconds, max_seconds):\n\u001b[1;32m---> 12\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(min_seconds, max_seconds))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Crawl alonhadat.com.vn using undetected-chromedriver from page 2 to 500\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "def random_sleep(min_seconds, max_seconds):\n",
    "    time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "def crawl_alonhadat_selenium(page_num, driver):\n",
    "    url = f\"https://alonhadat.com.vn/nha-dat/can-ban/nha-dat/1/ha-noi/trang--{page_num}.html\"\n",
    "    driver.get(url)\n",
    "    random_sleep(2, 4)  # Wait for page to load\n",
    "\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"div.content-item\")\n",
    "    results = []\n",
    "    for item in items:\n",
    "        try:\n",
    "            title_tag = item.find_element(By.CSS_SELECTOR, \"div.ct_title a\")\n",
    "            title = title_tag.text.strip()\n",
    "            link = \"https://alonhadat.com.vn\" + title_tag.get_attribute(\"href\")\n",
    "\n",
    "            date = item.find_element(By.CSS_SELECTOR, \"div.ct_date\").text.strip()\n",
    "\n",
    "            try:\n",
    "                area = item.find_element(By.CSS_SELECTOR, \"div.ct_dt\").text.strip().replace(\"Diện tích:\", \"\")\n",
    "            except NoSuchElementException:\n",
    "                area = \"\"\n",
    "\n",
    "            try:\n",
    "                price = item.find_element(By.CSS_SELECTOR, \"div.ct_price\").text.strip().replace(\"Giá:\", \"\")\n",
    "            except NoSuchElementException:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                floors = item.find_element(By.CSS_SELECTOR, \"span.floors\").get_attribute(\"title\")\n",
    "            except NoSuchElementException:\n",
    "                floors = \"\"\n",
    "\n",
    "            try:\n",
    "                bedrooms = item.find_element(By.CSS_SELECTOR, \"span.bedroom\").get_attribute(\"title\")\n",
    "            except NoSuchElementException:\n",
    "                bedrooms = \"\"\n",
    "\n",
    "            try:\n",
    "                address = item.find_element(By.CSS_SELECTOR, \"div.ct_dis\").text.strip()\n",
    "            except NoSuchElementException:\n",
    "                address = \"\"\n",
    "\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"url\": link,\n",
    "                \"date\": date,\n",
    "                \"area\": area,\n",
    "                \"price\": price,\n",
    "                \"floors\": floors,\n",
    "                \"bedrooms\": bedrooms,\n",
    "                \"address\": address,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing item: {e}\")\n",
    "    return results\n",
    "\n",
    "# --- Setup undetected-chromedriver ---\n",
    "chrome_options = uc.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")  # Remove if you want to see the browser\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "driver = uc.Chrome(options=chrome_options, version_main=136)\n",
    "\n",
    "# --- Crawl pages and save as JSONL ---\n",
    "output_folder = \"../Datasets/alonhadat.com/json_new\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "start_page = 15\n",
    "end_page = 500\n",
    "\n",
    "for page_num in range(start_page, end_page + 1):\n",
    "    print(f\"Crawling page {page_num}...\")\n",
    "    data = crawl_alonhadat_selenium(page_num, driver)\n",
    "    if data:\n",
    "        output_file = os.path.join(output_folder, f\"page_{page_num}.jsonl\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "            for d in data:\n",
    "                file.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved {len(data)} items to {output_file}\")\n",
    "    else:\n",
    "        print(f\"No data found for page {page_num}\")\n",
    "    random_sleep(1, 3)  # Be polite to the server\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
